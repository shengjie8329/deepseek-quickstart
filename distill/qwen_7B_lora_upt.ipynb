{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 Unsloth 对 DeepSeek-R1-Distill-Qwen-1.5B 模型进行 LoRA 微调\n",
    "\n",
    "本 Notebook 展示了如何使用 `unsloth` 库对 `deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B` 模型进行高效的 QLoRA (Low-Rank Adaptation) 微调。\n",
    "\n",
    "整个流程包括：\n",
    "1.  环境准备与库导入\n",
    "2.  加载预训练模型和分词器 (Tokenizer)。\n",
    "3.  在微调前，对模型进行简单的推理测试。\n",
    "4.  下载和格式化训练数据集\n",
    "5.  使用 `unsloth` 的 `FastLanguageModel` 来为模型添加 LoRA 适配器。\n",
    "6.  配置 `SFTTrainer` 监督微调训练配置。\n",
    "7.  启动训练，并观察 Loss 变化情况\n",
    "8.  保存微调后的模型\n",
    "9.  测试训练后的生成结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 环境准备与库导入\n",
    "\n",
    "首先，我们需要安装并导入所有必要的库。`transformers` 用于加载模型和分词器，`unsloth` 用于高效微调，`trl` 提供了 `SFTTrainer`，而 `datasets` 用于处理数据。\n",
    "\n",
    "**注意**: 在运行此 Notebook 之前，请确保已安装所有依赖包：\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 设置环境变量，下载器就会使用镜像站\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: datasets==3.6.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (3.6.0)\n",
      "Requirement already satisfied: pandas==2.3.1 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.3.1)\n",
      "Requirement already satisfied: peft==0.17.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.17.0)\n",
      "Requirement already satisfied: timm==1.0.19 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.0.19)\n",
      "Requirement already satisfied: torch==2.7.1 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (2.7.1)\n",
      "Requirement already satisfied: torchvision==0.22.1 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.22.1)\n",
      "Requirement already satisfied: transformers==4.55.2 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (4.55.2)\n",
      "Requirement already satisfied: trl==0.21.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.21.0)\n",
      "Requirement already satisfied: unsloth==2025.8.5 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (2025.8.5)\n",
      "Requirement already satisfied: unsloth_zoo==2025.8.4 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2025.8.4)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (2.2.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (0.34.4)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from pandas==2.3.1->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from pandas==2.3.1->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from pandas==2.3.1->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from peft==0.17.0->-r requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from peft==0.17.0->-r requirements.txt (line 3)) (1.10.1)\n",
      "Requirement already satisfied: safetensors in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from peft==0.17.0->-r requirements.txt (line 3)) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (3.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from torchvision==0.22.1->-r requirements.txt (line 6)) (11.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from transformers==4.55.2->-r requirements.txt (line 7)) (2025.7.33)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from transformers==4.55.2->-r requirements.txt (line 7)) (0.21.4)\n",
      "Requirement already satisfied: xformers>=0.0.27.post2 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from unsloth==2025.8.5->-r requirements.txt (line 9)) (0.0.31.post1)\n",
      "Requirement already satisfied: bitsandbytes in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from unsloth==2025.8.5->-r requirements.txt (line 9)) (0.47.0)\n",
      "Requirement already satisfied: tyro in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from unsloth==2025.8.5->-r requirements.txt (line 9)) (0.9.28)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from unsloth==2025.8.5->-r requirements.txt (line 9)) (0.2.1)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from unsloth==2025.8.5->-r requirements.txt (line 9)) (0.45.1)\n",
      "Requirement already satisfied: protobuf in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from unsloth==2025.8.5->-r requirements.txt (line 9)) (6.32.0)\n",
      "Requirement already satisfied: hf_transfer in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from unsloth==2025.8.5->-r requirements.txt (line 9)) (0.1.9)\n",
      "Requirement already satisfied: diffusers in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from unsloth==2025.8.5->-r requirements.txt (line 9)) (0.35.1)\n",
      "Requirement already satisfied: cut_cross_entropy in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from unsloth_zoo==2025.8.4->-r requirements.txt (line 10)) (25.1.1)\n",
      "Requirement already satisfied: msgspec in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from unsloth_zoo==2025.8.4->-r requirements.txt (line 10)) (0.19.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from triton==3.3.1->torch==2.7.1->-r requirements.txt (line 5)) (75.8.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (3.12.15)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets==3.6.0->-r requirements.txt (line 1)) (1.1.9)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.3.1->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.6.0->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.6.0->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.6.0->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.6.0->-r requirements.txt (line 1)) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from sympy>=1.13.3->torch==2.7.1->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: importlib_metadata in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from diffusers->unsloth==2025.8.5->-r requirements.txt (line 9)) (8.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from jinja2->torch==2.7.1->-r requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from tyro->unsloth==2025.8.5->-r requirements.txt (line 9)) (0.17.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from tyro->unsloth==2025.8.5->-r requirements.txt (line 9)) (14.1.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from tyro->unsloth==2025.8.5->-r requirements.txt (line 9)) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from tyro->unsloth==2025.8.5->-r requirements.txt (line 9)) (4.4.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (1.20.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth==2025.8.5->-r requirements.txt (line 9)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth==2025.8.5->-r requirements.txt (line 9)) (2.19.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from importlib_metadata->diffusers->unsloth==2025.8.5->-r requirements.txt (line 9)) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /root/miniconda3/envs/py310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth==2025.8.5->-r requirements.txt (line 9)) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt --trusted-host mirrors.aliyun.com -i http://mirrors.aliyun.com/pypi/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GenerationConfig, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 加载预训练模型和分词器 (Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.8.5: Fast Qwen2 patching. Transformers: 4.55.2.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 1. Max memory: 23.545 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75efee68f1244d198184afacc0983e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80205c523c14bc68682d5b211d43379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811869730eac455891b876883697e368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59662cac8a80455db3491ea754aadae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01509ab5cc264fac8c91c7800ecb76b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f801ebe15ca47bd99dc98a5f870ed06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671194a39c164ab2bab9fba05fa6df35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cf55cc703d4d66bd3725f4e2984943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 定义模型和一些基本参数\n",
    "max_seq_length = 8192\n",
    "dtype = None # None 表示自动选择 (Float16 a T4, V100, BFloat16 a Ampere)\n",
    "load_in_4bit = True # 使用 4bit 量化加载\n",
    "\n",
    "# 这是您的模型标识符，请替换为您正在使用的模型\n",
    "# 例如：\"qwen-1.5b_lora_model\"\n",
    "# model_name = \"qwen-1.5b_lora_model\" \n",
    "# model_name = \"unsloth/DeepSeek-R1-Distill-Qwen-1.5B\" \n",
    "model_name = \"unsloth/DeepSeek-R1-Distill-Qwen-7B-unsloth-bnb-4bit\" \n",
    "\n",
    "# 这一步会返回一个经过 Unsloth 优化的模型和一个分词器\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 微调前推理测试\n",
    "\n",
    "在对模型进行任何修改之前，我们先用它来生成一段文本，看看原始模型的表现如何。这可以作为我们微调效果的基准参考。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型推理的 Prompt 模板\n",
    "inference_prompt = \"\"\"以下是一条描述任务的指令，并配有一个提供进一步上下文的输入。\n",
    "请撰写一份恰当的回复，以完成该请求。\n",
    "在回答之前，请仔细思考该问题，并构建一个分步的思考过程，以确保回应的逻辑严谨和内容准确。\n",
    "\n",
    "\n",
    "### Instruction:\n",
    "你是一位医学专家，在临床推理、诊断学和治疗规划方面拥有深厚的专业知识。\n",
    "请回答以下医学问题。\n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "<think>{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "question = \"男，28岁，程序员，最近一周每天工作到半夜，感觉头晕、脖子疼，有时候还恶心。\"\n",
    "\n",
    "inputs = tokenizer([inference_prompt.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
    "attention_mask = inputs.input_ids.ne(tokenizer.pad_token_id).long().to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=1200,\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "嗯，我现在要处理这位28岁的程序员的病例。他最近工作到半夜，感觉头晕、脖子疼，有时还会恶心。首先，我需要考虑他的工作情况，因为他每天工作到很晚，这可能对他的身体有影响，比如疲劳、睡眠不足，这些都是可能导致头晕和恶心的原因。\n",
      "\n",
      "然后，我想到可能他有颈椎问题，尤其是如果他长时间低头看电脑，可能会压迫颈椎，导致疼痛和不适。这种情况比较常见，尤其是年轻人长时间使用电子设备的人群。\n",
      "\n",
      "接下来，我需要考虑他的症状是否符合某种特定的疾病。头晕和恶心可能与前庭系统有关，比如梅尼埃病，这是一种常见的神经系统疾病，可能导致恶心、呕吐、头晕等症状。但梅尼埃病通常会伴随耳部症状，比如听力减退或耳痛，如果他没有这些症状，可能排除这个可能性。\n",
      "\n",
      "另外，我想到他可能有睡眠障碍，比如失眠或者睡眠质量不好，导致白天精力不足，出现头晕和恶心。睡眠不足会导致大脑供血不足，从而产生疲劳感和不适感。\n",
      "\n",
      "我还应该考虑其他可能的健康问题，比如压力过大、焦虑或者抑郁，这些心理因素也可能导致类似的症状。但通常情况下，这些症状可能更持久，而不仅仅是工作到深夜引起的。\n",
      "\n",
      "然后，我需要建议他做一些检查，比如血常规、头部影像学检查（如CT或MRI）、神经功能检查，以及评估他的睡眠质量。这些检查可以帮助确定具体的原因。\n",
      "\n",
      "此外，我应该建议他进行一些缓解症状的活动，比如放松训练、深呼吸或者改变工作姿势，如果这些方法无效，可能需要进一步的医疗建议。\n",
      "\n",
      "总的来说，我需要综合考虑他的症状、生活方式以及可能的健康问题，然后给出一个全面的评估和建议。\n",
      "</think>\n",
      "\n",
      "根据您的描述，这位28岁的程序员出现头晕、脖子疼和恶心，可能与多种因素相关。以下是一份分步的分析报告：\n",
      "\n",
      "1. **初步评估**：\n",
      "   - **症状类型**：头晕、脖子疼痛、恶心。\n",
      "   - **可能原因**：\n",
      "     - 工作压力和疲劳。\n",
      "     - 颈部姿势不舒适。\n",
      "     - 心血管或神经系统问题。\n",
      "     - 梅尼埃病（需考虑是否有耳部症状）。\n",
      "     - 睡眠障碍。\n",
      "\n",
      "2. **建议检查**：\n",
      "   - **血液检查**：评估贫血或低血糖。\n",
      "   - **头部影像学检查**（如CT或MRI）：评估颈椎或头部结构。\n",
      "   - **神经功能评估**：评估神经功能完整性。\n",
      "   - **睡眠质量评估**：评估是否存在失眠或睡眠障碍。\n",
      "\n",
      "3. **初步建议**：\n",
      "   - **休息与调整工作方式**：建议他调整工作姿势，避免长时间低头。\n",
      "   - **改善睡眠**：建议他尝试改善睡眠质量，如定时入眠。\n",
      "   - **心理调节**：如果伴随焦虑或压力，建议进行心理调节。\n",
      "\n",
      "4. **进一步行动**：\n",
      "   - **就医检查**：尽快安排神经科或内科会诊，进行详细检查。\n",
      "   - **记录症状**：详细记录症状变化，方便后续诊断。\n",
      "\n",
      "5. **注意事项**：\n",
      "   - **避免剧烈运动**：避免影响颈椎。\n",
      "   - **保持水分摄入**：多喝水，防止脱水。\n",
      "   - **记录日志**：记录工作时间、症状变化，方便医生评估。\n",
      "\n",
      "通过以上步骤，可以更全面地评估和处理您的症状。建议在医生指导下进行详细检查和治疗。\n"
     ]
    }
   ],
   "source": [
    "print(response[0].split(\"### Response:\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. 下载和格式化训练数据集\n",
    "\n",
    "\n",
    "医学推理数据集：https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT/viewer/zh\n",
    "\n",
    "![dataset](images/dataset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练的 Prompt 模板\n",
    "train_prompt = \"\"\"以下是一条描述任务的指令，并配有一个提供进一步上下文的输入。\n",
    "请撰写一份恰当的回复，以完成该请求。\n",
    "在回答之前，请仔细思考该问题，并构建一个分步的思考过程，以确保回应的逻辑严谨和内容准确。\n",
    "\n",
    "\n",
    "### Instruction:\n",
    "你是一位医学专家，在临床推理、诊断学和治疗规划方面拥有深厚的专业知识。\n",
    "请回答以下医学问题。\n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "<think>\n",
    "{}\n",
    "</think>\n",
    "{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token # 添加 EOS Token\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    inputs = examples[\"Question\"]\n",
    "    cots = examples[\"Complex_CoT\"]\n",
    "    outputs = examples[\"Response\"]\n",
    "    texts = []\n",
    "    for input, cot, output in zip(inputs, cots, outputs):\n",
    "        # 将 EOS Token 添加到样本最后\n",
    "        text = train_prompt.format(input, cot, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", \"zh\", split = \"train\")\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'以下是一条描述任务的指令，并配有一个提供进一步上下文的输入。\\n请撰写一份恰当的回复，以完成该请求。\\n在回答之前，请仔细思考该问题，并构建一个分步的思考过程，以确保回应的逻辑严谨和内容准确。\\n\\n\\n### Instruction:\\n你是一位医学专家，在临床推理、诊断学和治疗规划方面拥有深厚的专业知识。\\n请回答以下医学问题。\\n\\n### Question:\\n根据描述，一个1岁的孩子在夏季头皮出现多处小结节，长期不愈合，且现在疮大如梅，溃破流脓，口不收敛，头皮下有空洞，患处皮肤增厚。这种病症在中医中诊断为什么病？\\n\\n### Response:\\n<think>\\n这个小孩子在夏天头皮上长了些小结节，一直都没好，后来变成了脓包，流了好多脓。想想夏天那么热，可能和湿热有关。才一岁的小孩，免疫力本来就不强，夏天的湿热没准就侵袭了身体。\\n\\n用中医的角度来看，出现小结节、再加上长期不愈合，这些症状让我想到了头疮。小孩子最容易得这些皮肤病，主要因为湿热在体表郁结。\\n\\n但再看看，头皮下还有空洞，这可能不止是简单的头疮。看起来病情挺严重的，也许是脓肿没治好。这样的情况中医中有时候叫做禿疮或者湿疮，也可能是另一种情况。\\n\\n等一下，头皮上的空洞和皮肤增厚更像是疾病已经深入到头皮下，这是不是说明有可能是流注或瘰疬？这些名字常描述头部或颈部的严重感染，特别是有化脓不愈合，又形成通道或空洞的情况。\\n\\n仔细想想，我怎么感觉这些症状更贴近瘰疬的表现？尤其考虑到孩子的年纪和夏天发生的季节性因素，湿热可能是主因，但可能也有火毒或者痰湿造成的滞留。\\n\\n回到基本的症状描述上看，这种长期不愈合又复杂的状况，如果结合中医更偏重的病名，是不是有可能是涉及更深层次的感染？\\n\\n再考虑一下，这应该不是单纯的瘰疬，得仔细分析头皮增厚并出现空洞这样的严重症状。中医里头，这样的表现可能更符合‘蚀疮’或‘头疽’。这些病名通常描述头部严重感染后的溃烂和组织坏死。\\n\\n看看季节和孩子的体质，夏天又湿又热，外邪很容易侵入头部，对孩子这么弱的免疫系统简直就是挑战。头疽这个病名听起来真是切合，因为它描述的感染严重，溃烂到出现空洞。\\n\\n不过，仔细琢磨后发现，还有个病名似乎更为合适，叫做‘蝼蛄疖’，这病在中医里专指像这种严重感染并伴有深部空洞的情况。它也涵盖了化脓和皮肤增厚这些症状。\\n\\n哦，该不会是夏季湿热，导致湿毒入侵，孩子的体质不能御，其病情发展成这样的感染？综合分析后我觉得‘蝼蛄疖’这个病名真是相当符合。\\n</think>\\n从中医的角度来看，你所描述的症状符合“蝼蛄疖”的病症。这种病症通常发生在头皮，表现为多处结节，溃破流脓，形成空洞，患处皮肤增厚且长期不愈合。湿热较重的夏季更容易导致这种病症的发展，特别是在免疫力较弱的儿童身上。建议结合中医的清热解毒、祛湿消肿的治疗方法进行处理，并配合专业的医疗建议进行详细诊断和治疗。\\n<｜end▁of▁sentence｜>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "以下是一条描述任务的指令，并配有一个提供进一步上下文的输入。\n",
       "请撰写一份恰当的回复，以完成该请求。\n",
       "在回答之前，请仔细思考该问题，并构建一个分步的思考过程，以确保回应的逻辑严谨和内容准确。\n",
       "\n",
       "\n",
       "### Instruction:\n",
       "你是一位医学专家，在临床推理、诊断学和治疗规划方面拥有深厚的专业知识。\n",
       "请回答以下医学问题。\n",
       "\n",
       "### Question:\n",
       "根据描述，一个1岁的孩子在夏季头皮出现多处小结节，长期不愈合，且现在疮大如梅，溃破流脓，口不收敛，头皮下有空洞，患处皮肤增厚。这种病症在中医中诊断为什么病？\n",
       "\n",
       "### Response:\n",
       "<think>\n",
       "这个小孩子在夏天头皮上长了些小结节，一直都没好，后来变成了脓包，流了好多脓。想想夏天那么热，可能和湿热有关。才一岁的小孩，免疫力本来就不强，夏天的湿热没准就侵袭了身体。\n",
       "\n",
       "用中医的角度来看，出现小结节、再加上长期不愈合，这些症状让我想到了头疮。小孩子最容易得这些皮肤病，主要因为湿热在体表郁结。\n",
       "\n",
       "但再看看，头皮下还有空洞，这可能不止是简单的头疮。看起来病情挺严重的，也许是脓肿没治好。这样的情况中医中有时候叫做禿疮或者湿疮，也可能是另一种情况。\n",
       "\n",
       "等一下，头皮上的空洞和皮肤增厚更像是疾病已经深入到头皮下，这是不是说明有可能是流注或瘰疬？这些名字常描述头部或颈部的严重感染，特别是有化脓不愈合，又形成通道或空洞的情况。\n",
       "\n",
       "仔细想想，我怎么感觉这些症状更贴近瘰疬的表现？尤其考虑到孩子的年纪和夏天发生的季节性因素，湿热可能是主因，但可能也有火毒或者痰湿造成的滞留。\n",
       "\n",
       "回到基本的症状描述上看，这种长期不愈合又复杂的状况，如果结合中医更偏重的病名，是不是有可能是涉及更深层次的感染？\n",
       "\n",
       "再考虑一下，这应该不是单纯的瘰疬，得仔细分析头皮增厚并出现空洞这样的严重症状。中医里头，这样的表现可能更符合‘蚀疮’或‘头疽’。这些病名通常描述头部严重感染后的溃烂和组织坏死。\n",
       "\n",
       "看看季节和孩子的体质，夏天又湿又热，外邪很容易侵入头部，对孩子这么弱的免疫系统简直就是挑战。头疽这个病名听起来真是切合，因为它描述的感染严重，溃烂到出现空洞。\n",
       "\n",
       "不过，仔细琢磨后发现，还有个病名似乎更为合适，叫做‘蝼蛄疖’，这病在中医里专指像这种严重感染并伴有深部空洞的情况。它也涵盖了化脓和皮肤增厚这些症状。\n",
       "\n",
       "哦，该不会是夏季湿热，导致湿毒入侵，孩子的体质不能御，其病情发展成这样的感染？综合分析后我觉得‘蝼蛄疖’这个病名真是相当符合。\n",
       "</think>\n",
       "从中医的角度来看，你所描述的症状符合“蝼蛄疖”的病症。这种病症通常发生在头皮，表现为多处结节，溃破流脓，形成空洞，患处皮肤增厚且长期不愈合。湿热较重的夏季更容易导致这种病症的发展，特别是在免疫力较弱的儿童身上。建议结合中医的清热解毒、祛湿消肿的治疗方法进行处理，并配合专业的医疗建议进行详细诊断和治疗。\n",
       "<｜end▁of▁sentence｜>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(dataset[0][\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 使用 Unsloth 添加 LoRA 适配器\n",
    "\n",
    "这是使用 `unsloth` 的核心步骤。我们调用 `FastLanguageModel.get_peft_model`，它会非常高效地为模型注入 LoRA 模块。\n",
    "\n",
    "- `r`: LoRA 的秩 (rank)，是控制模型复杂度和参数量的关键超参数。\n",
    "- `target_modules`: 指定要在哪些线性层（如注意力机制的 q, k, v, o 投影层）上应用 LoRA。\n",
    "- `lora_alpha`: LoRA 的缩放因子，通常设置为 `r` 的两倍或与 `r` 相同。\n",
    "- `use_gradient_checkpointing`: 一种节省显存的技术，对于训练大模型至关重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.8.5 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): Qwen2ForCausalLM(\n",
      "      (model): Qwen2Model(\n",
      "        (embed_tokens): Embedding(152064, 3584, padding_idx=151654)\n",
      "        (layers): ModuleList(\n",
      "          (0-3): 4 x Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=3584, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=18944, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "          )\n",
      "          (4): Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=18944, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "          )\n",
      "          (5-10): 6 x Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "          )\n",
      "          (11): Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=18944, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "          )\n",
      "          (12-23): 12 x Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "          )\n",
      "          (24-26): 3 x Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=18944, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "          )\n",
      "          (27): Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=3584, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=3584, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=18944, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "          )\n",
      "        )\n",
      "        (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "        (rotary_emb): LlamaRotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 因为 `model` 对象现在是由 Unsloth 创建的，它包含了所有必需的属性\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    target_modules=[\n",
    "      \"q_proj\",\n",
    "      \"k_proj\",\n",
    "      \"v_proj\",\n",
    "      \"o_proj\",\n",
    "      \"gate_proj\",\n",
    "      \"up_proj\",\n",
    "      \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=1432,\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")\n",
    "# 检查模型结构，确认 LoRA 适配器已添加\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 配置 SFTTrainer\n",
    "\n",
    "`SFTTrainer` (Supervised Fine-tuning Trainer) 是一个专门用于指令微调的训练器。我们需要配置 `TrainingArguments` 来指定所有的训练参数，如批量大小、学习率、优化器等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4c52c8e90644549d0eac251fbfe2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/20171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 64,\n",
    "        gradient_accumulation_steps = 2,\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 80,\n",
    "        learning_rate = 2e-4,\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 1432,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 开始训练\n",
    "\n",
    "一切准备就绪后，调用 `trainer.train()` 即可开始微调过程。训练结束后，会返回包含训练统计信息（如训练损失）的对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 80\n",
      "O^O/ \\_/ \\    Batch size per device = 64 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (64 x 2 x 1) = 128\n",
      " \"-____-\"     Trainable parameters = 40,370,176 of 7,655,986,688 (0.53% trained)\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 80\n",
      "O^O/ \\_/ \\    Batch size per device = 57 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (57 x 2 x 1) = 114\n",
      " \"-____-\"     Trainable parameters = 40,370,176 of 7,655,986,688 (0.53% trained)\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 80\n",
      "O^O/ \\_/ \\    Batch size per device = 51 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (51 x 2 x 1) = 102\n",
      " \"-____-\"     Trainable parameters = 40,370,176 of 7,655,986,688 (0.53% trained)\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 80\n",
      "O^O/ \\_/ \\    Batch size per device = 45 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (45 x 2 x 1) = 90\n",
      " \"-____-\"     Trainable parameters = 40,370,176 of 7,655,986,688 (0.53% trained)\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 80\n",
      "O^O/ \\_/ \\    Batch size per device = 40 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (40 x 2 x 1) = 80\n",
      " \"-____-\"     Trainable parameters = 40,370,176 of 7,655,986,688 (0.53% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 33:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.116200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.052500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.982800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.961600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.872700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.705600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.494400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.487400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.382500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.361300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.325200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.297700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.173900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.089600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.089700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.049900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.063700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.097400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.070500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.020900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.974100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.983200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.035600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.990500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.988300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>2.015500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.964900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.991800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.962400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.960300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.968600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.979500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.982000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.987400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.942500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.939700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.999600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.917300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.983100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.950600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.920300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.977500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.913000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.967900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.960300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.934000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.994200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.893800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.887100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.927100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.960100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.943700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.921300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.919200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.891200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.919100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.924200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>1.945600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.911800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.919400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.905500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1.957000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.933900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.922100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.946200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainOutput(global_step=80, training_loss=2.112584951519966, metrics={'train_runtime': 2059.2829, 'train_samples_per_second': 3.108, 'train_steps_per_second': 0.039, 'total_flos': 2.6008130525110272e+17, 'train_loss': 2.112584951519966})\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()\n",
    "\n",
    "# 打印训练统计信息\n",
    "print(trainer_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 保存微调后的模型（Lora）\n",
    "\n",
    "训练完成后，您可以再次进行推理，比较微调后的模型与原始模型的差异。如果对结果满意，可以使用 `model.save_pretrained(\"your_lora_adapter_path\")` 来保存训练好的 LoRA 适配器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"qwen-7b_lora_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('qwen-7b_lora_model/tokenizer_config.json',\n",
       " 'qwen-7b_lora_model/special_tokens_map.json',\n",
       " 'qwen-7b_lora_model/chat_template.jinja',\n",
       " 'qwen-7b_lora_model/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"qwen-7b_lora_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型保存方式二选一（要么使用上面的分开保存，要么使用这里的合并 Lora 保存）\n",
    "# model.save_pretrained_merged(\"qwen-1.5b_lora_model\", tokenizer, save_method=\"merged_16bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 测试训练后的生成结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "question=\"一个患有急性阑尾炎的病人已经发病5天，腹痛稍有减轻但仍然发热，在体检时发现右下腹有压痛的包块，此时应如何处理？\", # Question\n",
    "inputs = tokenizer([inference_prompt.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=1000,\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "这位病人已经有5天的急性阑尾炎了，腹痛虽然稍微减轻了，但还是有点疼痛。而且发热也是个问题。现在体检的时候，右下腹有一个压痛的包块。嗯，这说明可能有感染了。\n",
      "\n",
      "首先，我得想到阑尾炎通常会伴随感染，所以这个包块可能就是感染的迹象。不过，包块可能不是阑尾炎的唯一表现，也可能是其他问题，比如急性胆囊炎或者急性胃炎。\n",
      "\n",
      "哦，急性阑尾炎常伴有右下腹的压痛，这可能是包块的信号。但是，如果包块有压痛，而且发热的话，那情况就不一样了。发热一般和感染有关，比如细菌感染，这让我觉得可能不是阑尾炎。\n",
      "\n",
      "再想想，阑尾炎一般不会有发热，除非是细菌感染，但这种情况下，包块和发热都会出现。那这个包块是不是代表感染了某种细菌呢？\n",
      "\n",
      "查一下，如果包块是感染性的，那我们需要考虑可能的感染原因，比如胆囊炎或者急性胃炎，这些都会导致发热和包块。\n",
      "\n",
      "不过，别急着下结论，得再仔细想想。急性阑尾炎一般不会伴随发热，除非是细菌感染。那这个包块和发热可能指向细菌感染，这让我怀疑是急性胆囊炎。\n",
      "\n",
      "嗯，我需要进一步确认，但根据目前的信息，这个包块和发热提示可能是细菌感染引起的急性胆囊炎。\n",
      "\n",
      "不过，也有可能是其他原因，比如急性胃炎，虽然通常不伴随发热，但有时候也会有，所以也不能排除。\n",
      "\n",
      "啊，这个包块的压痛和发热，让我更倾向于细菌感染的可能性，尤其是急性胆囊炎。\n",
      "\n",
      "好吧，看来我得按照这个思路来处理，可能需要进一步检查，比如B超或者做一个影像学检查，看看包块的具体情况。\n",
      "\n",
      "总之，这个包块和发热提示可能是细菌感染引起的急性胆囊炎，我得记住这个情况，以便采取相应的治疗措施。\n",
      "</think>\n",
      "根据您的描述，这个病人有5天的急性阑尾炎病史，腹痛虽然稍有减轻，但仍然存在发热和右下腹的压痛包块。这些症状提示可能存在细菌感染，尤其是急性胆囊炎的可能性较大。急性阑尾炎通常不会伴随发热，除非是细菌感染，而发热和包块的压痛更常与急性胆囊炎相关联。因此，建议进行进一步的影像学检查，如B超，以明确包块的性质和位置。如果包块呈感染性表现，可能需要考虑急性胆囊炎的诊断。建议根据影像学结果和症状变化采取相应的治疗措施。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(output[0].split(\"### Response:\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(question: str, model, tokenizer, inference_prompt: str, max_new_tokens: int = 1024) -> str:\n",
    "    \"\"\"\n",
    "    使用指定的模型和分词器为给定的医学问题生成响应。\n",
    "\n",
    "    Args:\n",
    "        question (str): 需要模型回答的医学问题。\n",
    "        model: 已加载的 Unsloth/Hugging Face 模型。\n",
    "        tokenizer: 对应的分词器。\n",
    "        inference_prompt (str): 用于格式化输入的 f-string 模板。\n",
    "        max_new_tokens (int, optional): 生成响应的最大 token 数量。默认为 1024。\n",
    "\n",
    "    Returns:\n",
    "        str: 模型生成的响应文本，已去除 prompt 部分。\n",
    "    \"\"\"\n",
    "    # 1. 使用模板格式化输入\n",
    "    prompt = inference_prompt.format(\n",
    "        question, # 填充问题\n",
    "        \"\",       # 留空，让模型生成 CoT 和 Response\n",
    "    )\n",
    "\n",
    "    # 2. 将格式化后的 prompt 进行分词，并转移到 GPU\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # 3. 使用模型生成输出\n",
    "    # use_cache=True 用于加速解码过程\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        use_cache=True,\n",
    "    )\n",
    "    \n",
    "    # 4. 将生成的 token 解码为文本\n",
    "    # skip_special_tokens=True 会移除像 EOS_TOKEN 这样的特殊标记\n",
    "    decoded_output = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "    # 5. 切分字符串，只返回 \"### Response:\" 之后的部分\n",
    "    # 使用 .split() 分割并获取响应内容，.strip() 用于去除可能存在的前后空白字符\n",
    "    response_part = decoded_output.split(\"### Response:\")\n",
    "    if len(response_part) > 1:\n",
    "        return response_part[1].strip()\n",
    "    else:\n",
    "        # 如果模型没有生成 \"### Response:\" 标记，则返回整个生成内容以供调试\n",
    "        return decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 模型回答 ====================\n",
      "<think>\n",
      "60岁男性患者，右胸疼，X线显示右肋膈角消失，提示可能有胸腔积液。这种情况下，肺结核伴右侧胸腔积液，我得考虑一下胸水的性质。胸水的性质可能影响诊断和治疗，比如是否是脓液还是清液，或者有其他成分。通常，了解胸水的成分对于治疗和诊断非常关键。\n",
      "\n",
      "首先，我想到常规的实验室检查，比如血常规和肝肾功能检查。这些检查可以帮助我们了解患者的总体健康状况，以及是否存在感染、炎症或者其他代谢问题。但是，它们可能无法直接提供关于胸水的详细信息。\n",
      "\n",
      "嗯，如果我想更深入地了解胸水的性质，可能需要更直接的分析。实验室检查中，血培养和胸水培养是常用的手段。血培养可以检测是否存在特定病原体，比如肺炎链球菌，而胸水培养则可以分析胸水中的病原体，如细菌、病毒或者真菌。这些信息对于判断胸水的性质和进行针对性治疗非常重要。\n",
      "\n",
      "再想想，还有没有其他更直接的方法呢？比如影像学检查，比如超声，可以提供胸水的外观信息。但影像学检查只能大致了解胸水的液量和外观，不能提供具体的成分分析。\n",
      "\n",
      "哦，对了，还有一个办法，那就是胸水穿刺，获取胸水样本进行进一步的分析。通过胸水穿刺，可以将胸水样本送至实验室进行各种分析，如培养、基因检测、病毒检测等。这些检测可以提供关于胸水的成分和病原体的信息，这对诊断和治疗非常有帮助。\n",
      "\n",
      "不过，胸水穿刺可能在临床上不太常见，因为操作相对复杂，成本也较高。不过，对于了解胸水的性质，这是最直接有效的方法之一。\n",
      "\n",
      "综上所述，为了更准确了解胸水的成分和性质，血培养和胸水培养是最直接的实验室检查手段。此外，胸水穿刺也是有效的方法，可以提供更详细的信息。\n",
      "</think>\n",
      "对于一名66岁男性患者，出现右侧胸疼并在X线检查中显示右侧肋膈角消失，诊断为肺结核伴右侧胸腔积液，了解胸水的性质需要进行更深入的实验室检查。以下是可能对了解胸水性质有帮助的实验室检查：\n",
      "\n",
      "1. **血培养**：通过血培养可以检测是否存在特定病原体，如肺炎链球菌、结核菌等，这有助于了解胸水中的病原体种类。\n",
      "\n",
      "2. **胸水培养**：胸水培养是直接分析胸水成分和病原体的常用方法。通过培养可以确定胸水中的病原体类型，如细菌、病毒或真菌，从而明确胸水的性质。\n",
      "\n",
      "3. **胸水穿刺**：胸水穿刺可以获取胸水样本，进一步进行基因检测、病毒检测等，帮助了解胸水的成分和病原体的种类。\n",
      "\n",
      "这些检查方法能够提供关于胸水成分和病原体的详细信息，有助于诊断和治疗计划的制定。\n"
     ]
    }
   ],
   "source": [
    "my_question = \"对于一名60岁男性患者，出现右侧胸疼并在X线检查中显示右侧肋膈角消失，诊断为肺结核伴右侧胸腔积液，请问哪一项实验室检查对了解胸水的性质更有帮助？\"\n",
    "\n",
    "response = generate_response(my_question, model, tokenizer, inference_prompt)\n",
    "print(\"==================== 模型回答 ====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 模型回答 ====================\n",
      "<think>\n",
      "嗯，这位28岁的程序员，长期熬夜，最近突然觉得头晕目眩，有点恶心，这让我想到他可能有高血压。不过，也有可能是其他什么问题呢？\n",
      "\n",
      "首先，我得考虑他最近的生活习惯。长期熬夜，可能影响了他的血压。长时间处于黑暗和低光环境下，这会降低身体对光的敏感度，从而降低视网膜中的视杆状细胞的兴奋性，这可能引起视杆状细胞减少，进而导致血压升高。\n",
      "\n",
      "但是，高血压也会伴随一些症状，比如口渴、多尿、多饮和视物模糊。这位患者没有提到这些症状，所以可能不是高血压。\n",
      "\n",
      "那，他最近有没有其他症状呢？比如头痛、口渴或视物模糊？如果他没有这些症状，那可能不是高血压。\n",
      "\n",
      "再想想，他长期熬夜，可能还有其他原因。比如，他可能在睡眠质量上出了问题。睡眠不足，会导致身体的血压升高。\n",
      "\n",
      "也有可能是他的工作压力大，导致压力性高血压。压力确实会导致血压升高，尤其是长时间处于紧张状态。\n",
      "\n",
      "不过，患者没有提到压力性高血压的症状，比如口渴、多尿、视物模糊，所以可能不是压力性高血压。\n",
      "\n",
      "还有，他最近突然感觉头晕目眩，这可能是因为血压上升引起的脑供血不足。但是，如果没有口渴、多尿和视物模糊等症状，可能不是高血压。\n",
      "\n",
      "再想想，他最近可能有其他疾病。比如，他可能有糖尿病，或者他可能有睡眠障碍，比如失眠或者睡眠呼吸暂停。\n",
      "\n",
      "也有可能是其他原因，比如他最近开始吃某些药物，或者他有某些生活习惯导致血压异常。\n",
      "\n",
      "嗯，看来我得考虑更多的可能性，比如睡眠障碍、压力性高血压或者其他慢性病。\n",
      "\n",
      "不过，从目前的症状来看，他可能有高血压，但也需要排除其他可能性。\n",
      "\n",
      "或者，他的头晕目眩可能是由于其他原因引起的，比如脑供血不足、贫血、脑水肿等。\n",
      "\n",
      "不过，患者没有提到这些症状，所以可能还是高血压的可能性更大。\n",
      "\n",
      "嗯，综合来看，虽然他没有提到一些高血压的症状，但长期熬夜可能影响血压，导致头晕目眩。\n",
      "\n",
      "所以，我还是倾向于认为他可能有高血压，虽然需要进一步的检查来确认。\n",
      "</think>\n",
      "根据这位28岁程序员的描述，他长期熬夜且最近突然出现头晕目眩，这种情况可能与高血压有关。长期熬夜可能导致视杆状细胞减少，进而引发血压升高。然而，患者没有提到口渴、多尿、视物模糊等高血压的典型症状，这可能需要进一步确认。建议进行详细的体检和血压监测，以明确诊断。如果血压异常，可以考虑进一步的治疗，以排除其他潜在的健康问题。\n"
     ]
    }
   ],
   "source": [
    "my_question = \"对于一名 28 岁的男性患者，工作是程序员，常年熬夜，最近突然感觉头晕目眩，甚至有点恶心。请问有可能是什么疾病？\"\n",
    "\n",
    "response = generate_response(my_question, model, tokenizer, inference_prompt)\n",
    "print(\"==================== 模型回答 ====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
